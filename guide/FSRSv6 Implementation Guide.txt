Problem:
- need to implement an advanced SRS system (preferbly FSRSv6 since its the best one) 
but encounter several problems that idk if its suitable using a traditional implementation method: 
- there are a lot of words  
- for normal SRS schedule, new words will return after days, but in my game, people can do many quizes per day. and if the words they already learn only return after days, they keep learning tons and tons of new words and revise nothing. my games has fast gameplay, so i think they should sometimes encounter the words they already did in the same day. unlike normal flashcard app, you encounter the word very quick, you switch to new one very quick also, you understand what i mean?
- two different games: text input game should be harder, idk how each game affect the SRS.


Solution:
This support:
* High-volume, fast-paced gameplay
* Dynamic cloze generation and word re-encounters on the same day
* Per-word SRS scheduling that works within cloze game contexts
* Differentiated scoring based on game type (MCQ vs. text input)
* Maximizing flexibility instead of capping learned words per day

## Integration Strategy

### Word-Level SRS Metadata

Each vocabulary **word** in the app should be treated as an FSRS “card” with its own SRS state.  At minimum, you need to store **per-word fields** that FSRS uses. A good starting point is the `Card` schema from the TS-FSRS library, which includes fields like *due*, *stability*, *difficulty*, *last\_review*, *reps*, *lapses*, etc. For example:

```ts
type FSRSCard = {
  due: Date;              // next due date/time
  stability: number;      // retention stability (days to drop from 100%→90%)
  difficulty: number;     // difficulty rating of the word
  elapsed_days: number;   // days since last review
  scheduled_days: number; // days until next scheduled review
  learning_steps: number; // current step in the learning phase (if any)
  reps: number;           // total reviews done
  lapses: number;         // total failures/“again” presses
  state: string;          // e.g. "New", "Learning", "Review", "Relearning"
  last_review?: Date;     // timestamp of the last review, if any
  // ... plus any app-specific info, e.g. word ID or content ...
};
```

You should **persist** this state for each user and word. In a Next.js/TypeScript app, one approach is to define a database model or table with columns matching these fields (and a foreign key linking to the user and the word itself). For example, a SQL schema or Prisma model might look like:

| Column           | Type         | Description                                         |
| ---------------- | ------------ | --------------------------------------------------- |
| `id`             | UUID/INT     | Primary key                                         |
| `user_id`        | UUID/INT     | Reference to user account                           |
| `word`           | TEXT/VARCHAR | The vocabulary word or its ID                       |
| `state`          | ENUM         | Current FSRS state (New/Learning/Review/Relearning) |
| `stability`      | FLOAT        | FSRS stability value (days to 90% recall)           |
| `difficulty`     | FLOAT        | FSRS difficulty value (≈1–10 range)                 |
| `due`            | DATETIME     | Next review due timestamp                           |
| `reps`           | INT          | Total review count                                  |
| `lapses`         | INT          | Total times failed (“Again”)                        |
| `learning_steps` | INT          | Current learning sub-step                           |
| `last_review`    | DATETIME     | Timestamp of most recent review                     |
| *others...*      |              | e.g. `interval_days`, etc.                          |

> **Tip:** In a NoSQL or JSON store, you could store the entire `FSRSCard` object as a JSON document. In TypeScript, make a corresponding interface to ensure type safety.

Whenever the user reviews a word in your app, you will load that word’s FSRSCard state, apply FSRS to compute the next state, and then save it back. The TS-FSRS library (see below) can help update the state fields automatically (it outputs the updated card and a `ReviewLog` when you feed it a rating).

### Collecting Performance Feedback

FSRS requires a discrete **rating** for each review: typically **Again (0)**, **Hard (1)**, **Good (2)**, or **Easy (3)**. In an Anki-like UI, these correspond to how well the learner thought they did. In your cloze games, you must **map the user’s performance** to one of these FSRS ratings. Possible strategies:

* **Correct vs Incorrect:** At a minimum, mark a wrong answer as **Again (0)** and a correct answer as at least **Good (2)**.
* **Effort or Hints:** If your game shows hints or allows multiple tries, penalize use of hints or multiple attempts by giving **Hard (1)** instead of Good.
* **Speed:** Optionally, use response time: very fast correct answers could be treated as **Easy (3)**, while slower but correct answers are **Good (2)**.
* **Full vs Partial Recall:** For cloze input, if the user gets the word with minor spelling errors, that might be Hard or Good; perfect recall could be Easy.
* **Mode Adjustment:** Because multiple-choice (recognition) is generally easier than free recall, you might calibrate thresholds differently. For example, only award **Easy** on MC if the user answers immediately or with a bonus criterion; or consider MC correct as only **Good** to be conservative.

**Example mapping (illustrative):**

* *Cloze Text (free recall)*

  * Correct on first try (fast): **Good** or **Easy**
  * Correct after hint/second try: **Hard**
  * Fail (after all attempts): **Again**

* *Cloze Multiple Choice*

  * Correct (on any guess): **Good** (since recognition is easier)
  * Correct after eliminating one option or hint: **Hard**
  * Incorrect final: **Again**

These rules should be tuned by trial. The key is consistency: feed FSRS a rating 0–3 after each word review based on the outcome. You may also weight multiple encounters of the same word in one session. For simplicity, you could update FSRS after each encounter (so each attempt is a review), or aggregate a session’s results (e.g. use the worst rating of the session). FSRS v5 can handle multiple reviews in one day if you enable its short-term mode (see below).

### Same-Day Scheduling

A critical requirement is **re-exposing words within the same day**, since users play many games back-to-back. By default, FSRS schedules the *next due* date usually days ahead. However, FSRS v5 allows short-interval reviews as well. To leverage this:

* **Enable FSRS short-term mode:** When initializing FSRS (e.g. via `fsrs = new FSRS(params)`), set the parameter that enables same-day scheduling (often called `enable_short_term` in implementations). This allows FSRS to propose intervals shorter than 1 day when learning. Note: out-of-the-box it won’t go below \~4 hours, but you can adjust learning steps to achieve closer spacing if needed.
* **Use “learning” steps:** In your card schema, `learning_steps` tracks how many quick repeats have occurred. Define a few short learning steps (e.g. 0.25 days, 0.5 days) for new or failed cards, so that if a user fails a word, FSRS schedules it a few hours later rather than next day.
* **Session re-queuing:** Apart from FSRS, you can also implement an *in-session review queue*. For example, keep a small buffer of recently learned or failed words and pop them back into the game after some time (e.g. after 5 other words or after X minutes). This ensures immediate reinforcement even if FSRS didn’t schedule it yet.
* **Cover end-of-day reviews:** As the day winds down, you might want to force any due reviews that day. You can run FSRS on all cards with `due <= now` and include them in the next session queue.

In summary, a hybrid approach works best: use FSRS for long-term scheduling (days/weeks ahead), but also inject short-term reviews via learning steps or an auxiliary queue.  In practice, FSRS-5’s same-day support means you could call something like `fsrs.next(card, now, rating)` multiple times in a day and it will produce shorter intervals when appropriate. Just be sure to record each review with its exact timestamp so FSRS can factor it in.

## Game Mode Differentiation

Your app has two cloze game modes: **multiple-choice** and **text-input**. Since these differ in difficulty and guessing chance, adjust FSRS updates accordingly:

* **Scoring model:** Treat **multiple-choice** as an easier form of recall. One approach is to *cap* the highest rating on MC mode. For example, only award **Easy (3)** if the user answers extremely quickly or with high confidence; otherwise a correct MC answer might be **Good (2)**. For **text input**, allow **Easy** for quick, flawless answers.
* **Time/Attempts weighting:** If the user uses a hint or has multiple attempts, downgrade the rating. E.g. MC with one wrong guess could be Hard (1); text with a spelling error could be Hard.
* **Adjust difficulty updates:** FSRS updates both stability and difficulty values on each review. You might apply a small multiplier to difficulty if the word was tested in MC mode (since MC underestimates true difficulty). For example, after a successful MC answer, you could manually decrease `stability` less (i.e. make review less effective) or slightly increase the difficulty value, to compensate. Conversely, text-input successes could reduce difficulty more. This effectively weights the update.
* **Separate tracking (optional):** In some designs, developers create *two* FSRS entries per word (one for MC experience and one for text), but merge results. This is complex; usually adjusting the rating mapping is simpler.

Ultimately, you want FSRS to learn that “getting an MC question right” is not as strong evidence of mastery as “writing it out correctly,” so it spaces the word accordingly. This calibration will likely require some testing with real users to tune the thresholds.

## Flexible Scheduling for High Throughput

Since your app has **no strict daily limits** on new words or sessions, you must keep FSRS flexible:

* **Adjust retention target:** If users are adding *hundreds* of new words per day, a 90% retention target may create an unmanageable backlog of reviews. FSRS allows lowering the retention threshold to reduce future reviews. For instance, simulations show dropping from 90% to \~70% retention can **drastically cut daily review counts** while still maintaining learning. You might expose this as a setting (or choose a sensible default) so that FSRS is tuned for high-throughput learning.
* **No hard caps:** Unlike Anki’s “200 new cards per day” limits, FSRS itself does not impose a cap. You can allow unlimited new cards; FSRS will simply schedule more reviews down the line (or suggest lowering retention). However, for user experience you may still want to moderate daily new cards.
* **Hybrid review queue:** To balance immediate vs long-term spacing, maintain two queues: a **“fast review” queue** for same-day reinforcement (as discussed above) and the usual **due reviews queue** for scheduled long-term reviews. For example, after each game session, you could enqueue some cards from that session into the fast queue for a short quiz. Meanwhile, FSRS calculates next-day (or later) reviews as usual.
* **Use FSRS maximum interval:** FSRS parameters include a *maximum interval* cap. You can configure this so words don’t get scheduled years out (especially if retention is low). Setting an upper bound helps keep the review backlog reachable.
* **Random spacing (fuzz):** FSRS supports adding a small random jitter to scheduled times (`enable_fuzz`). This can prevent review “storms” by spreading items out, which might help in high-volume scenarios.

A **hybrid strategy** might look like this: whenever a word is reviewed (in any mode), update its FSRS state. If FSRS schedules it within the next 24 hours, simply mark it for review in that timeframe. Regardless, also add the word to an in-session repetition pool. At the end of each play session (or every N minutes), pop a few words from this pool for quick review quizzes. This lets the user reinforce words immediately, while FSRS handles when they should see them in subsequent days.

## User Experience (Subtle Reinforcement)

To encourage users to follow FSRS-driven review schedules without breaking the game immersion, integrate gentle UI cues:

* **“Review due” indicators:** Tag or badge words that are scheduled for review soon. For example, when a word comes up in a sentence, show a small icon (★ or “R”) if it is due within the next day. This signals importance without interrupting play.
* **Prioritize in-game appearance:** Weight the word selection algorithm so due words are *slightly* more likely to appear. For instance, if generating a mixed-session of new and review words, include all due words first. You can even give “bonus points” for correct answers on due words to incentivize users to answer carefully.
* **End-of-session review:** At the end of each practice session, pop up a quick “flashcard” review round of some due or recently learned words (much like Duolingo’s practice reminders).
* **Progress indicators:** Show visual progress bars for each word (e.g. a retention meter or “streak” that resets on lapses). This is optional but can motivate users.
* **Settings and feedback:** Inform users that the system is “remembering” their performance. For instance, when switching from MC to text mode for the same word, note it is a “challenge review” because it’s due again.

The goal is to make spaced repetition part of the game’s natural flow. Avoid heavy-handed flashcard drills; instead slip in reviews as normal game items or mini-games, highlighting them subtly.

## Code Examples & Resources

Here are some practical pointers for implementation:

* **FSRS Libraries:** Use an existing FSRS library rather than reimplementing the math. For a TypeScript/Next.js app, [**ts-fsrs**](https://github.com/open-spaced-repetition/ts-fsrs) is ideal. Install it via npm/yarn:

  ```bash
  npm install ts-fsrs
  ```

  It provides `FSRS`, `Card`, and enums like `Rating` for use in your code.

* **Scheduling update example (TypeScript):**

  ```ts
  import { FSRS, createEmptyCard, Rating } from 'ts-fsrs';

  // Initialize scheduler with default or custom params
  const scheduler = new FSRS(/* optional FSRSParameters */);

  // Load or create card state for a word
  let card = fetchCardFromDB(wordId); // { due, stability, difficulty, ... } or createEmptyCard();

  // When user reviews the word, map game outcome to a rating:
  const userRating: Rating = /* determine from game */;
  const now = new Date();

  // Compute next state:
  const { card: updatedCard, log: reviewLog } = scheduler.next(card, now, userRating);

  // Save updatedCard back to DB, log the review if needed
  saveCardToDB(wordId, updatedCard);
  ```

  This code uses `FSRS.next()` to process a single review (given the current card state and the user’s rating) and returns both the new card state and a `ReviewLog` object.

* **Fetching due words:** To find what to review each day, simply query all cards where `due <= now`. Sort by priority if desired, and feed them into the next game session.

* **Sample JSON format:** You might store or send card state as JSON. For example:

  ```json
  {
    "word": "apple",
    "due": "2025-05-22T10:00:00.000Z",
    "stability": 14.2,
    "difficulty": 3.8,
    "reps": 5,
    "lapses": 1,
    "state": "Review",
    "last_review": "2025-05-20T09:15:30.000Z"
  }
  ```

  This mirrors the `Card` fields used by TS-FSRS. Storing dates as ISO strings (or DB date types) is recommended.

* **Official FSRS Resources:** Refer to the **open-spaced-repetition** GitHub org for FSRS implementations and docs. The [ts-fsrs README and docs](https://open-spaced-repetition.github.io/ts-fsrs/) cover usage and parameters, and the [awesome-fsrs](https://github.com/open-spaced-repetition/awesome-fsrs) repo lists other language bindings (Rust, Python, etc.). Anki’s [official FAQ](https://faqs.ankiweb.net/what-spaced-repetition-algorithm.html) also summarizes FSRS vs SM-2.

* **FSRS v5 Changes:** For the latest specifics on version 5, see the FSRS release notes (e.g. [py-fsrs v5.0.0](https://github.com/open-spaced-repetition/py-fsrs/releases/tag/v5.0.0)) and Anki discussion forums. FSRS-5 mainly adds intra-day scheduling and an optimizer tweak.

## Summary

To implement FSRS v5 in your React/Next.js vocabulary game:

1. **Model each word as an FSRS card**, storing fields (due, stability, difficulty, etc.) per user in your database.
2. **Collect game results** and map them to FSRS ratings (Again/Hard/Good/Easy).  Update the card via `fsrs.next(card, now, rating)` on each review.
3. **Schedule same-day reviews** by enabling FSRS short-term mode and/or by queuing immediate repeats for just-encountered words.  Use FSRS v5’s ability to handle short intervals.
4. **Differentiate game modes** by calibrating the rating logic or difficulty updates for MC vs text input, so that easier modes yield slightly less aggressive spacing.
5. **Maintain flexibility** by adjusting FSRS retention targets or caps, allowing many new words per day while still scheduling reviews (for example, lower the target retention to reduce review volume). Use a hybrid system of FSRS scheduling plus quick in-session quizzes for reinforcement.
6. **Enhance UX** with subtle cues: tag review-due words in the game UI, prioritize them in sessions, and consider bonus points or color-coding to signal an item’s review status.

By following these steps and leveraging libraries like TS-FSRS, a developer can fully integrate FSRS v5 into a modern Next.js/TypeScript learning app, bringing state-of-the-art spaced repetition to dynamic cloze games.

**Sources:** Official FSRS documentation and examples.